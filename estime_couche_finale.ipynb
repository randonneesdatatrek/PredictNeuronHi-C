{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "listed-record",
   "metadata": {},
   "source": [
    "# Estimation de la couche finale d'Akita sur les données de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "departmental-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boolean-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bright-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-aspect",
   "metadata": {},
   "source": [
    "## Chargement des prédictions de l'avant-dernière couche d'Akita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "predpath = \"/home/bureau/projects/def-bureau/bureau/ran-donnees/PredictNeuronHi-C/akita_pred_sans_final_lisse/\"\n",
    "predfile = predpath + \"preds.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alpine-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"preds.h5\" (mode r)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = h5py.File(predfile, 'r')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conservative-congo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7619, 99681, 48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['preds'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-revolution",
   "metadata": {},
   "source": [
    "## Chargement des cibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vocal-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetfile = \"/home/bureau/projects/def-bureau/bureau/distiller/iPSC/data/1s/seqs_cov/0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strong-shipping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"0.h5\" (mode r)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = h5py.File(targetfile, 'r')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imported-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7619, 99681)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les données d'élaboration sont les 7619 premières\n",
    "train_targets = targets['targets'][:7619,]\n",
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-night",
   "metadata": {},
   "source": [
    "## Test de la régression linéaire sur un lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "smaller-message",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99681, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(pred['preds'][0,:pred['preds'].shape[1],:pred['preds'].shape[2]],dtype=np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "otherwise-tenant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99681, 49)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "micro-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0 = sm.OLS(train_targets[0,:],X)\n",
    "mod0.fit = mod0.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "treated-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.384</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.384</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1294.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Mar 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:42:41</td>     <th>  Log-Likelihood:    </th> <td> -45880.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 99681</td>      <th>  AIC:               </th> <td>9.186e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 99632</td>      <th>  BIC:               </th> <td>9.232e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    48</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.6099</td> <td>    0.019</td> <td>  -32.636</td> <td> 0.000</td> <td>   -0.647</td> <td>   -0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2036</td> <td>    0.051</td> <td>    4.001</td> <td> 0.000</td> <td>    0.104</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2304</td> <td>    0.026</td> <td>    8.868</td> <td> 0.000</td> <td>    0.179</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3926</td> <td>    0.027</td> <td>   14.412</td> <td> 0.000</td> <td>    0.339</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.6268</td> <td>    0.037</td> <td>  -16.721</td> <td> 0.000</td> <td>   -0.700</td> <td>   -0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.5518</td> <td>    0.043</td> <td>   12.979</td> <td> 0.000</td> <td>    0.468</td> <td>    0.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0086</td> <td>    0.019</td> <td>   -0.445</td> <td> 0.656</td> <td>   -0.046</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.4214</td> <td>    0.044</td> <td>    9.586</td> <td> 0.000</td> <td>    0.335</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.2067</td> <td>    0.016</td> <td>  -13.012</td> <td> 0.000</td> <td>   -0.238</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.5161</td> <td>    0.030</td> <td>   17.013</td> <td> 0.000</td> <td>    0.457</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.2607</td> <td>    0.017</td> <td>  -15.731</td> <td> 0.000</td> <td>   -0.293</td> <td>   -0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.3635</td> <td>    0.026</td> <td>  -13.720</td> <td> 0.000</td> <td>   -0.415</td> <td>   -0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -1.3288</td> <td>    0.044</td> <td>  -30.001</td> <td> 0.000</td> <td>   -1.416</td> <td>   -1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0365</td> <td>    0.013</td> <td>   -2.775</td> <td> 0.006</td> <td>   -0.062</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -1.4972</td> <td>    0.039</td> <td>  -38.625</td> <td> 0.000</td> <td>   -1.573</td> <td>   -1.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.2013</td> <td>    0.050</td> <td>   -4.028</td> <td> 0.000</td> <td>   -0.299</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0729</td> <td>    0.032</td> <td>    2.262</td> <td> 0.024</td> <td>    0.010</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.8973</td> <td>    0.038</td> <td>  -23.320</td> <td> 0.000</td> <td>   -0.973</td> <td>   -0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.5722</td> <td>    0.048</td> <td>   12.028</td> <td> 0.000</td> <td>    0.479</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.2319</td> <td>    0.024</td> <td>   -9.757</td> <td> 0.000</td> <td>   -0.278</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.3824</td> <td>    0.018</td> <td>   21.263</td> <td> 0.000</td> <td>    0.347</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0708</td> <td>    0.049</td> <td>    1.456</td> <td> 0.145</td> <td>   -0.025</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0715</td> <td>    0.017</td> <td>   -4.297</td> <td> 0.000</td> <td>   -0.104</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.2968</td> <td>    0.048</td> <td>   -6.218</td> <td> 0.000</td> <td>   -0.390</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.1630</td> <td>    0.023</td> <td>   -7.038</td> <td> 0.000</td> <td>   -0.208</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.6044</td> <td>    0.041</td> <td>  -14.752</td> <td> 0.000</td> <td>   -0.685</td> <td>   -0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0885</td> <td>    0.012</td> <td>    7.505</td> <td> 0.000</td> <td>    0.065</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.6791</td> <td>    0.047</td> <td>  -14.450</td> <td> 0.000</td> <td>   -0.771</td> <td>   -0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.3352</td> <td>    0.025</td> <td>  -13.299</td> <td> 0.000</td> <td>   -0.385</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.0959</td> <td>    0.031</td> <td>   -3.106</td> <td> 0.002</td> <td>   -0.156</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -1.3957</td> <td>    0.070</td> <td>  -19.816</td> <td> 0.000</td> <td>   -1.534</td> <td>   -1.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.6979</td> <td>    0.038</td> <td>  -18.448</td> <td> 0.000</td> <td>   -0.772</td> <td>   -0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.0624</td> <td>    0.044</td> <td>   -1.430</td> <td> 0.153</td> <td>   -0.148</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    1.1508</td> <td>    0.045</td> <td>   25.698</td> <td> 0.000</td> <td>    1.063</td> <td>    1.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    1.4121</td> <td>    0.060</td> <td>   23.510</td> <td> 0.000</td> <td>    1.294</td> <td>    1.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.3260</td> <td>    0.021</td> <td>   15.880</td> <td> 0.000</td> <td>    0.286</td> <td>    0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.8593</td> <td>    0.047</td> <td>  -18.310</td> <td> 0.000</td> <td>   -0.951</td> <td>   -0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.3851</td> <td>    0.015</td> <td>   26.238</td> <td> 0.000</td> <td>    0.356</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.2667</td> <td>    0.022</td> <td>  -12.039</td> <td> 0.000</td> <td>   -0.310</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1819</td> <td>    0.013</td> <td>  -14.106</td> <td> 0.000</td> <td>   -0.207</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.2167</td> <td>    0.028</td> <td>    7.767</td> <td> 0.000</td> <td>    0.162</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.0076</td> <td>    0.023</td> <td>   -0.330</td> <td> 0.741</td> <td>   -0.052</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.3936</td> <td>    0.028</td> <td>   14.267</td> <td> 0.000</td> <td>    0.340</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.0610</td> <td>    0.031</td> <td>   -1.991</td> <td> 0.047</td> <td>   -0.121</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1240</td> <td>    0.015</td> <td>   -8.063</td> <td> 0.000</td> <td>   -0.154</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.6638</td> <td>    0.063</td> <td>  -10.609</td> <td> 0.000</td> <td>   -0.786</td> <td>   -0.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.5148</td> <td>    0.045</td> <td>   11.419</td> <td> 0.000</td> <td>    0.426</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.1294</td> <td>    0.015</td> <td>    8.423</td> <td> 0.000</td> <td>    0.099</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.7009</td> <td>    0.049</td> <td>   14.260</td> <td> 0.000</td> <td>    0.605</td> <td>    0.797</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>957.317</td> <th>  Durbin-Watson:     </th> <td>   0.250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1166.336</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.172</td>  <th>  Prob(JB):          </th> <td>5.41e-254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.403</td>  <th>  Cond. No.          </th> <td>    109.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.384\n",
       "Model:                            OLS   Adj. R-squared:                  0.384\n",
       "Method:                 Least Squares   F-statistic:                     1294.\n",
       "Date:                Mon, 22 Mar 2021   Prob (F-statistic):               0.00\n",
       "Time:                        17:42:41   Log-Likelihood:                -45880.\n",
       "No. Observations:               99681   AIC:                         9.186e+04\n",
       "Df Residuals:                   99632   BIC:                         9.232e+04\n",
       "Df Model:                          48                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.6099      0.019    -32.636      0.000      -0.647      -0.573\n",
       "x1             0.2036      0.051      4.001      0.000       0.104       0.303\n",
       "x2             0.2304      0.026      8.868      0.000       0.179       0.281\n",
       "x3             0.3926      0.027     14.412      0.000       0.339       0.446\n",
       "x4            -0.6268      0.037    -16.721      0.000      -0.700      -0.553\n",
       "x5             0.5518      0.043     12.979      0.000       0.468       0.635\n",
       "x6            -0.0086      0.019     -0.445      0.656      -0.046       0.029\n",
       "x7             0.4214      0.044      9.586      0.000       0.335       0.508\n",
       "x8            -0.2067      0.016    -13.012      0.000      -0.238      -0.176\n",
       "x9             0.5161      0.030     17.013      0.000       0.457       0.576\n",
       "x10           -0.2607      0.017    -15.731      0.000      -0.293      -0.228\n",
       "x11           -0.3635      0.026    -13.720      0.000      -0.415      -0.312\n",
       "x12           -1.3288      0.044    -30.001      0.000      -1.416      -1.242\n",
       "x13           -0.0365      0.013     -2.775      0.006      -0.062      -0.011\n",
       "x14           -1.4972      0.039    -38.625      0.000      -1.573      -1.421\n",
       "x15           -0.2013      0.050     -4.028      0.000      -0.299      -0.103\n",
       "x16            0.0729      0.032      2.262      0.024       0.010       0.136\n",
       "x17           -0.8973      0.038    -23.320      0.000      -0.973      -0.822\n",
       "x18            0.5722      0.048     12.028      0.000       0.479       0.665\n",
       "x19           -0.2319      0.024     -9.757      0.000      -0.278      -0.185\n",
       "x20            0.3824      0.018     21.263      0.000       0.347       0.418\n",
       "x21            0.0708      0.049      1.456      0.145      -0.025       0.166\n",
       "x22           -0.0715      0.017     -4.297      0.000      -0.104      -0.039\n",
       "x23           -0.2968      0.048     -6.218      0.000      -0.390      -0.203\n",
       "x24           -0.1630      0.023     -7.038      0.000      -0.208      -0.118\n",
       "x25           -0.6044      0.041    -14.752      0.000      -0.685      -0.524\n",
       "x26            0.0885      0.012      7.505      0.000       0.065       0.112\n",
       "x27           -0.6791      0.047    -14.450      0.000      -0.771      -0.587\n",
       "x28           -0.3352      0.025    -13.299      0.000      -0.385      -0.286\n",
       "x29           -0.0959      0.031     -3.106      0.002      -0.156      -0.035\n",
       "x30           -1.3957      0.070    -19.816      0.000      -1.534      -1.258\n",
       "x31           -0.6979      0.038    -18.448      0.000      -0.772      -0.624\n",
       "x32           -0.0624      0.044     -1.430      0.153      -0.148       0.023\n",
       "x33            1.1508      0.045     25.698      0.000       1.063       1.239\n",
       "x34            1.4121      0.060     23.510      0.000       1.294       1.530\n",
       "x35            0.3260      0.021     15.880      0.000       0.286       0.366\n",
       "x36           -0.8593      0.047    -18.310      0.000      -0.951      -0.767\n",
       "x37            0.3851      0.015     26.238      0.000       0.356       0.414\n",
       "x38           -0.2667      0.022    -12.039      0.000      -0.310      -0.223\n",
       "x39           -0.1819      0.013    -14.106      0.000      -0.207      -0.157\n",
       "x40            0.2167      0.028      7.767      0.000       0.162       0.271\n",
       "x41           -0.0076      0.023     -0.330      0.741      -0.052       0.037\n",
       "x42            0.3936      0.028     14.267      0.000       0.340       0.448\n",
       "x43           -0.0610      0.031     -1.991      0.047      -0.121      -0.001\n",
       "x44           -0.1240      0.015     -8.063      0.000      -0.154      -0.094\n",
       "x45           -0.6638      0.063    -10.609      0.000      -0.786      -0.541\n",
       "x46            0.5148      0.045     11.419      0.000       0.426       0.603\n",
       "x47            0.1294      0.015      8.423      0.000       0.099       0.160\n",
       "x48            0.7009      0.049     14.260      0.000       0.605       0.797\n",
       "==============================================================================\n",
       "Omnibus:                      957.317   Durbin-Watson:                   0.250\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1166.336\n",
       "Skew:                          -0.172   Prob(JB):                    5.41e-254\n",
       "Kurtosis:                       3.403   Cond. No.                         109.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod0.fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-society",
   "metadata": {},
   "source": [
    "## Régression linéaire pour tous les lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cooked-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "#from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dutch-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de coefficients\n",
    "npar = pred['preds'].shape[2]+1\n",
    "beta_mat = np.zeros((pred['preds'].shape[0],npar))\n",
    "xx_mat = np.zeros((pred['preds'].shape[0],npar,npar))\n",
    "xx_sum = np.zeros((npar,npar))\n",
    "inputs=range(pred['preds'].shape[0])\n",
    " \n",
    "def compute_LM(i):\n",
    "    # Extraction de la matrice de prédicteurs\n",
    "    X = np.array(pred['preds'][i,:pred['preds'].shape[1],:pred['preds'].shape[2]],dtype=np.float32)\n",
    "    X = sm.add_constant(X)\n",
    "    mod = sm.OLS(train_targets[i,:],X)\n",
    "    mod.fit = mod.fit()\n",
    "    return(mod.fit.params,np.linalg.inv(mod.fit.normalized_cov_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bibliographic-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processeurs\n",
    "ncpus = int(os.environ.get('SLURM_CPUS_PER_TASK',default=1))\n",
    "pool = mp.Pool(processes=ncpus)\n",
    "ncpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "liquid-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle sur les lots\n",
    "#processed_list = Parallel(n_jobs=num_cores)(delayed(compute_LM)(i=j)for j in inputs)\n",
    "processed_list = [pool.apply_async(compute_LM,args=(j,)) for j in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attended-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des sorties\n",
    "beta_vec = np.zeros(npar)\n",
    "for i in range(len(processed_list)):\n",
    "    w_s = processed_list[i].get()\n",
    "    beta_mat[i,] = w_s[0]\n",
    "    xx_mat[i,] = w_s[1]\n",
    "    xx_sum = xx_sum + xx_mat[i,]\n",
    "    beta_vec = beta_vec + np.matmul(xx_mat[i,],beta_mat[i,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des coefficients et matrices X'X dans un fichier h5\n",
    "hf = h5py.File('regress_res.h5', 'w')\n",
    "hf.create_dataset('beta',data=beta_mat)\n",
    "hf.create_dataset('xx',data=xx_mat)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "designing-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 49)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inversion de la somme des matrices de variance-covariance\n",
    "cov = np.linalg.inv(xx_sum)\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-monte",
   "metadata": {},
   "source": [
    "## Calcul de l'estimation des moindre carrés des coefficients par la méthode de Duncan (1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "interracial-christianity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.51718975e-01,  2.58807564e-02,  1.19163258e-02,  2.93938664e-03,\n",
       "       -6.61203015e-02, -9.59953129e-03,  2.14761907e-02, -1.19366767e-02,\n",
       "       -1.60369408e-02, -1.61147827e-02,  8.02132985e-03,  2.82380447e-03,\n",
       "        8.35432573e-02, -2.65990678e-02, -6.22075246e-02, -8.04181107e-02,\n",
       "        3.63725560e-02,  6.38940941e-02,  7.72009556e-02,  5.82915440e-02,\n",
       "       -5.51047975e-02, -1.85974530e-02, -1.36052504e-02,  5.71852089e-03,\n",
       "       -4.88973728e-02,  3.70050306e-02,  1.69409949e-02, -6.48172132e-02,\n",
       "        1.16648122e-02, -6.57552656e-04, -1.15045980e-01,  4.25135569e-02,\n",
       "        3.24065033e-02, -1.53930364e-01,  2.30432403e-02,  1.79276000e-02,\n",
       "        2.47894460e-02,  3.85482915e-03, -3.03972085e-02,  6.91088834e-03,\n",
       "       -7.33670091e-02, -5.59882123e-02,  1.22114142e-04, -1.38735699e-02,\n",
       "        8.35359012e-03,  4.15396286e-02,  7.20825595e-02, -2.02940561e-02,\n",
       "        1.50881877e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_final = np.matmul(cov,beta_vec)\n",
    "beta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-abuse",
   "metadata": {},
   "source": [
    "## Sauvegarde des estimations et de leur \"covariance\" dans des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "coated-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dat = pd.DataFrame(beta_final)\n",
    "beta_dat.to_csv(\"beta_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "static-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dat = pd.DataFrame(cov)\n",
    "cov_dat.to_csv(\"cov_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "entitled-suspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.81481137e-08, -4.12235824e-08,  1.41750080e-08,\n",
       "        -3.32145501e-09, -3.71675485e-08],\n",
       "       [-4.12235824e-08,  9.49145029e-07, -4.95143495e-08,\n",
       "        -1.86696885e-07,  3.89394626e-08],\n",
       "       [ 1.41750080e-08, -4.95143495e-08,  2.92871352e-07,\n",
       "         2.32118580e-08, -1.63626059e-08],\n",
       "       [-3.32145501e-09, -1.86696885e-07,  2.32118580e-08,\n",
       "         3.16309781e-07, -2.57895686e-08],\n",
       "       [-3.71675485e-08,  3.89394626e-08, -1.63626059e-08,\n",
       "        -2.57895686e-08,  3.44028424e-07]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expensive-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39902382, -1.58300518,  0.04490336,  0.19111755,  1.38983807,\n",
       "       -0.11763738, -0.61290574,  0.38687857,  0.54073968,  0.97442179,\n",
       "       -0.14012155,  1.03036003, -0.45871646,  0.76067161,  0.492336  ,\n",
       "        2.27783643,  0.82602485, -1.61935474, -0.00281972, -0.44336617,\n",
       "        0.34788088, -0.27392429, -0.11659872, -0.82399811,  0.31070679,\n",
       "        0.2155158 , -0.17044884,  0.30385767, -0.65210356,  0.04488354,\n",
       "        0.55268289,  1.1322074 , -0.50240073,  2.04427803,  0.15309189,\n",
       "       -0.46671125,  1.00288281, -0.25352349,  0.89545993,  0.28146678,\n",
       "       -1.0748859 , -0.4149236 , -0.09360222,  0.16673444, -0.75240393,\n",
       "       -1.21771065, -1.31073787, -0.15942402, -0.39437459])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_mat[1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-guarantee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
