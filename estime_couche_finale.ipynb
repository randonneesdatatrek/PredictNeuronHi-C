{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation de la couche finale d'Akita sur les données de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des prédictions de l'avant-dernière couche d'Akita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predpath = \"/home/bureau/projects/def-bureau/bureau/ran-donnees/PredictNeuronHi-C/akita_pred_sans_final/\"\n",
    "predfile = predpath + \"preds.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"preds.h5\" (mode r)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = h5py.File(predfile, 'r')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7617, 99681, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['preds'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des cibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetfile = \"/home/bureau/projects/def-bureau/bureau/distiller/iPSC/data/1m/seqs_cov/0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"0.h5\" (mode r)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = h5py.File(targetfile, 'r')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7617, 99681)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les données d'élaboration sont les 7617 premières\n",
    "train_targets = targets['targets'][:7617,]\n",
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de la régression linéaire sur un lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99681, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(pred['preds'][0,:pred['preds'].shape[1],:pred['preds'].shape[2]],dtype=np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99681, 49)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0 = sm.OLS(train_targets[0,:],X)\n",
    "mod0.fit = mod0.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.384</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.384</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1294.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Mar 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:42:41</td>     <th>  Log-Likelihood:    </th> <td> -45880.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 99681</td>      <th>  AIC:               </th> <td>9.186e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 99632</td>      <th>  BIC:               </th> <td>9.232e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    48</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.6099</td> <td>    0.019</td> <td>  -32.636</td> <td> 0.000</td> <td>   -0.647</td> <td>   -0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2036</td> <td>    0.051</td> <td>    4.001</td> <td> 0.000</td> <td>    0.104</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2304</td> <td>    0.026</td> <td>    8.868</td> <td> 0.000</td> <td>    0.179</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3926</td> <td>    0.027</td> <td>   14.412</td> <td> 0.000</td> <td>    0.339</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.6268</td> <td>    0.037</td> <td>  -16.721</td> <td> 0.000</td> <td>   -0.700</td> <td>   -0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.5518</td> <td>    0.043</td> <td>   12.979</td> <td> 0.000</td> <td>    0.468</td> <td>    0.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0086</td> <td>    0.019</td> <td>   -0.445</td> <td> 0.656</td> <td>   -0.046</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.4214</td> <td>    0.044</td> <td>    9.586</td> <td> 0.000</td> <td>    0.335</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.2067</td> <td>    0.016</td> <td>  -13.012</td> <td> 0.000</td> <td>   -0.238</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.5161</td> <td>    0.030</td> <td>   17.013</td> <td> 0.000</td> <td>    0.457</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.2607</td> <td>    0.017</td> <td>  -15.731</td> <td> 0.000</td> <td>   -0.293</td> <td>   -0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.3635</td> <td>    0.026</td> <td>  -13.720</td> <td> 0.000</td> <td>   -0.415</td> <td>   -0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -1.3288</td> <td>    0.044</td> <td>  -30.001</td> <td> 0.000</td> <td>   -1.416</td> <td>   -1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0365</td> <td>    0.013</td> <td>   -2.775</td> <td> 0.006</td> <td>   -0.062</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -1.4972</td> <td>    0.039</td> <td>  -38.625</td> <td> 0.000</td> <td>   -1.573</td> <td>   -1.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.2013</td> <td>    0.050</td> <td>   -4.028</td> <td> 0.000</td> <td>   -0.299</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0729</td> <td>    0.032</td> <td>    2.262</td> <td> 0.024</td> <td>    0.010</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.8973</td> <td>    0.038</td> <td>  -23.320</td> <td> 0.000</td> <td>   -0.973</td> <td>   -0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.5722</td> <td>    0.048</td> <td>   12.028</td> <td> 0.000</td> <td>    0.479</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.2319</td> <td>    0.024</td> <td>   -9.757</td> <td> 0.000</td> <td>   -0.278</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.3824</td> <td>    0.018</td> <td>   21.263</td> <td> 0.000</td> <td>    0.347</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0708</td> <td>    0.049</td> <td>    1.456</td> <td> 0.145</td> <td>   -0.025</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0715</td> <td>    0.017</td> <td>   -4.297</td> <td> 0.000</td> <td>   -0.104</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.2968</td> <td>    0.048</td> <td>   -6.218</td> <td> 0.000</td> <td>   -0.390</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.1630</td> <td>    0.023</td> <td>   -7.038</td> <td> 0.000</td> <td>   -0.208</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.6044</td> <td>    0.041</td> <td>  -14.752</td> <td> 0.000</td> <td>   -0.685</td> <td>   -0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0885</td> <td>    0.012</td> <td>    7.505</td> <td> 0.000</td> <td>    0.065</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.6791</td> <td>    0.047</td> <td>  -14.450</td> <td> 0.000</td> <td>   -0.771</td> <td>   -0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.3352</td> <td>    0.025</td> <td>  -13.299</td> <td> 0.000</td> <td>   -0.385</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.0959</td> <td>    0.031</td> <td>   -3.106</td> <td> 0.002</td> <td>   -0.156</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -1.3957</td> <td>    0.070</td> <td>  -19.816</td> <td> 0.000</td> <td>   -1.534</td> <td>   -1.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.6979</td> <td>    0.038</td> <td>  -18.448</td> <td> 0.000</td> <td>   -0.772</td> <td>   -0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.0624</td> <td>    0.044</td> <td>   -1.430</td> <td> 0.153</td> <td>   -0.148</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    1.1508</td> <td>    0.045</td> <td>   25.698</td> <td> 0.000</td> <td>    1.063</td> <td>    1.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    1.4121</td> <td>    0.060</td> <td>   23.510</td> <td> 0.000</td> <td>    1.294</td> <td>    1.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.3260</td> <td>    0.021</td> <td>   15.880</td> <td> 0.000</td> <td>    0.286</td> <td>    0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.8593</td> <td>    0.047</td> <td>  -18.310</td> <td> 0.000</td> <td>   -0.951</td> <td>   -0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.3851</td> <td>    0.015</td> <td>   26.238</td> <td> 0.000</td> <td>    0.356</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.2667</td> <td>    0.022</td> <td>  -12.039</td> <td> 0.000</td> <td>   -0.310</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1819</td> <td>    0.013</td> <td>  -14.106</td> <td> 0.000</td> <td>   -0.207</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.2167</td> <td>    0.028</td> <td>    7.767</td> <td> 0.000</td> <td>    0.162</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.0076</td> <td>    0.023</td> <td>   -0.330</td> <td> 0.741</td> <td>   -0.052</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.3936</td> <td>    0.028</td> <td>   14.267</td> <td> 0.000</td> <td>    0.340</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.0610</td> <td>    0.031</td> <td>   -1.991</td> <td> 0.047</td> <td>   -0.121</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1240</td> <td>    0.015</td> <td>   -8.063</td> <td> 0.000</td> <td>   -0.154</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.6638</td> <td>    0.063</td> <td>  -10.609</td> <td> 0.000</td> <td>   -0.786</td> <td>   -0.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.5148</td> <td>    0.045</td> <td>   11.419</td> <td> 0.000</td> <td>    0.426</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.1294</td> <td>    0.015</td> <td>    8.423</td> <td> 0.000</td> <td>    0.099</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.7009</td> <td>    0.049</td> <td>   14.260</td> <td> 0.000</td> <td>    0.605</td> <td>    0.797</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>957.317</td> <th>  Durbin-Watson:     </th> <td>   0.250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1166.336</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.172</td>  <th>  Prob(JB):          </th> <td>5.41e-254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.403</td>  <th>  Cond. No.          </th> <td>    109.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.384\n",
       "Model:                            OLS   Adj. R-squared:                  0.384\n",
       "Method:                 Least Squares   F-statistic:                     1294.\n",
       "Date:                Mon, 22 Mar 2021   Prob (F-statistic):               0.00\n",
       "Time:                        17:42:41   Log-Likelihood:                -45880.\n",
       "No. Observations:               99681   AIC:                         9.186e+04\n",
       "Df Residuals:                   99632   BIC:                         9.232e+04\n",
       "Df Model:                          48                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.6099      0.019    -32.636      0.000      -0.647      -0.573\n",
       "x1             0.2036      0.051      4.001      0.000       0.104       0.303\n",
       "x2             0.2304      0.026      8.868      0.000       0.179       0.281\n",
       "x3             0.3926      0.027     14.412      0.000       0.339       0.446\n",
       "x4            -0.6268      0.037    -16.721      0.000      -0.700      -0.553\n",
       "x5             0.5518      0.043     12.979      0.000       0.468       0.635\n",
       "x6            -0.0086      0.019     -0.445      0.656      -0.046       0.029\n",
       "x7             0.4214      0.044      9.586      0.000       0.335       0.508\n",
       "x8            -0.2067      0.016    -13.012      0.000      -0.238      -0.176\n",
       "x9             0.5161      0.030     17.013      0.000       0.457       0.576\n",
       "x10           -0.2607      0.017    -15.731      0.000      -0.293      -0.228\n",
       "x11           -0.3635      0.026    -13.720      0.000      -0.415      -0.312\n",
       "x12           -1.3288      0.044    -30.001      0.000      -1.416      -1.242\n",
       "x13           -0.0365      0.013     -2.775      0.006      -0.062      -0.011\n",
       "x14           -1.4972      0.039    -38.625      0.000      -1.573      -1.421\n",
       "x15           -0.2013      0.050     -4.028      0.000      -0.299      -0.103\n",
       "x16            0.0729      0.032      2.262      0.024       0.010       0.136\n",
       "x17           -0.8973      0.038    -23.320      0.000      -0.973      -0.822\n",
       "x18            0.5722      0.048     12.028      0.000       0.479       0.665\n",
       "x19           -0.2319      0.024     -9.757      0.000      -0.278      -0.185\n",
       "x20            0.3824      0.018     21.263      0.000       0.347       0.418\n",
       "x21            0.0708      0.049      1.456      0.145      -0.025       0.166\n",
       "x22           -0.0715      0.017     -4.297      0.000      -0.104      -0.039\n",
       "x23           -0.2968      0.048     -6.218      0.000      -0.390      -0.203\n",
       "x24           -0.1630      0.023     -7.038      0.000      -0.208      -0.118\n",
       "x25           -0.6044      0.041    -14.752      0.000      -0.685      -0.524\n",
       "x26            0.0885      0.012      7.505      0.000       0.065       0.112\n",
       "x27           -0.6791      0.047    -14.450      0.000      -0.771      -0.587\n",
       "x28           -0.3352      0.025    -13.299      0.000      -0.385      -0.286\n",
       "x29           -0.0959      0.031     -3.106      0.002      -0.156      -0.035\n",
       "x30           -1.3957      0.070    -19.816      0.000      -1.534      -1.258\n",
       "x31           -0.6979      0.038    -18.448      0.000      -0.772      -0.624\n",
       "x32           -0.0624      0.044     -1.430      0.153      -0.148       0.023\n",
       "x33            1.1508      0.045     25.698      0.000       1.063       1.239\n",
       "x34            1.4121      0.060     23.510      0.000       1.294       1.530\n",
       "x35            0.3260      0.021     15.880      0.000       0.286       0.366\n",
       "x36           -0.8593      0.047    -18.310      0.000      -0.951      -0.767\n",
       "x37            0.3851      0.015     26.238      0.000       0.356       0.414\n",
       "x38           -0.2667      0.022    -12.039      0.000      -0.310      -0.223\n",
       "x39           -0.1819      0.013    -14.106      0.000      -0.207      -0.157\n",
       "x40            0.2167      0.028      7.767      0.000       0.162       0.271\n",
       "x41           -0.0076      0.023     -0.330      0.741      -0.052       0.037\n",
       "x42            0.3936      0.028     14.267      0.000       0.340       0.448\n",
       "x43           -0.0610      0.031     -1.991      0.047      -0.121      -0.001\n",
       "x44           -0.1240      0.015     -8.063      0.000      -0.154      -0.094\n",
       "x45           -0.6638      0.063    -10.609      0.000      -0.786      -0.541\n",
       "x46            0.5148      0.045     11.419      0.000       0.426       0.603\n",
       "x47            0.1294      0.015      8.423      0.000       0.099       0.160\n",
       "x48            0.7009      0.049     14.260      0.000       0.605       0.797\n",
       "==============================================================================\n",
       "Omnibus:                      957.317   Durbin-Watson:                   0.250\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1166.336\n",
       "Skew:                          -0.172   Prob(JB):                    5.41e-254\n",
       "Kurtosis:                       3.403   Cond. No.                         109.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod0.fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire pour tous les lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de coefficients\n",
    "npar = pred['preds'].shape[2]+1\n",
    "beta_mat = np.zeros((pred['preds'].shape[0],npar))\n",
    "xx_mat = np.zeros((pred['preds'].shape[0],npar,npar))\n",
    "xx_sum = np.zeros((npar,npar))\n",
    "# Boucle sur les lots\n",
    "for i in range(pred['preds'].shape[0]):\n",
    "    # Extraction de la matrice de prédicteurs\n",
    "    X = np.array(pred['preds'][i,:pred['preds'].shape[1],:pred['preds'].shape[2]],dtype=np.float32)\n",
    "    X = sm.add_constant(X)\n",
    "    mod = sm.OLS(train_targets[i,:],X)\n",
    "    mod.fit = mod.fit()\n",
    "    beta_mat[i,] = mod.fit.params\n",
    "    xx_mat[i,] = np.linalg.inv(mod.fit.normalized_cov_params)\n",
    "    xx_sum = xx_sum + xx_mat[i,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 49)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inversion de la somme des matrices de variance-covariance\n",
    "cov = np.linalg.inv(xx_sum)\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de l'estimation des moindre carrés des coefficients par la méthode de Duncan (1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14365427,  0.03716058,  0.00913258,  0.00646756, -0.06668746,\n",
       "       -0.01382421,  0.02838141, -0.0331073 ,  0.00930681, -0.02549175,\n",
       "        0.00200029, -0.0287394 ,  0.0241323 , -0.00530443, -0.03601322,\n",
       "       -0.07475538,  0.02253388,  0.05151738,  0.08732799,  0.0392308 ,\n",
       "       -0.05292522, -0.04670851, -0.00482304,  0.0405061 , -0.05858171,\n",
       "       -0.00043112,  0.01271191, -0.06108393,  0.03988695, -0.01182013,\n",
       "       -0.12794256,  0.04344437,  0.05920321, -0.1368567 ,  0.05342997,\n",
       "        0.03366394,  0.03072383, -0.00156791, -0.0258284 ,  0.0145607 ,\n",
       "       -0.07120221, -0.04266817, -0.02940599,  0.01157515,  0.01895863,\n",
       "        0.02440564,  0.07749435, -0.0216817 , -0.04454472])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_vec = np.zeros(npar)\n",
    "for i in range(pred['preds'].shape[0]):\n",
    "    beta_vec = beta_vec + np.matmul(xx_mat[i,],beta_mat[i,])\n",
    "beta_final = np.matmul(cov,beta_vec)\n",
    "beta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des estimations et de leur \"covariance\" dans des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dat = pd.DataFrame(beta_final)\n",
    "beta_dat.to_csv(\"beta_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dat = pd.DataFrame(cov)\n",
    "cov_dat.to_csv(\"cov_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.81623490e-08, -4.12422926e-08,  1.41749005e-08,\n",
       "        -3.32535393e-09, -3.71748822e-08],\n",
       "       [-4.12422926e-08,  9.49262669e-07, -4.95162185e-08,\n",
       "        -1.86750756e-07,  3.89316001e-08],\n",
       "       [ 1.41749005e-08, -4.95162185e-08,  2.92936146e-07,\n",
       "         2.32040006e-08, -1.63872665e-08],\n",
       "       [-3.32535393e-09, -1.86750756e-07,  2.32040006e-08,\n",
       "         3.16390862e-07, -2.57898510e-08],\n",
       "       [-3.71748822e-08,  3.89316001e-08, -1.63872665e-08,\n",
       "        -2.57898510e-08,  3.44137587e-07]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12876581,  0.59567164, -0.10425682, -0.58185182,  0.79916392,\n",
       "        1.07649432, -0.00874789,  0.50833046,  0.68730851,  0.80410378,\n",
       "       -0.31972619, -0.09315363, -0.13082563,  0.0176904 , -0.94442803,\n",
       "        0.38489407, -1.42583074, -1.75421009, -0.20989175,  0.25105951,\n",
       "       -0.41360156, -1.88181577,  0.45778917, -0.85761263,  0.0346512 ,\n",
       "        0.83140108,  0.22325217,  1.67136999,  0.81944921, -0.45695786,\n",
       "       -1.88022625,  0.91111394,  0.7087806 , -0.70370532,  1.25285385,\n",
       "       -0.43602057, -0.03923691,  0.07304694,  0.521765  ,  0.39678756,\n",
       "       -0.08339328,  0.49544063,  0.28782657, -0.55793223,  0.40057599,\n",
       "       -1.73714716, -0.60790451, -0.69965674,  0.47394429])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_mat[1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
